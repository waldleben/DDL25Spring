{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first lab tutorial presents the findings and uses part of the experimental methodology from the [original Federated Learning](https://arxiv.org/pdf/1602.05629.pdf) paper. In horizontal federated learning, all clients have access to the same complete model architecture, which they train on local data, sharing information about model updates but not their data.\n",
    "\n",
    "Before starting, make sure to follow the overall setup for the labs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://blogs.nvidia.com/blog/what-is-federated-learning/\" target=\"_blank\">\n",
    "    <img src=\"https://blogs.nvidia.com/wp-content/uploads/2019/10/federated_learning_animation_still_white.png\" alt=\"FL Visualization\" style=\"width:50%;\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before anything else, we download, load, and preprocess the [MNIST dataset](https://archive.ics.uci.edu/dataset/683/mnist+database+of+handwritten+digits), which we will use for all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:05<00:00, 1.94MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 313kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.10MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.65MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "data_path = \"./data\"\n",
    "ETA = \"\\N{GREEK SMALL LETTER ETA}\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # normalize by training set mean and standard deviation\n",
    "    # resulting data has mean=0 and std=1\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
    "test_loader = DataLoader(\n",
    "    datasets.MNIST(data_path, train=False, download=False, transform=transform),\n",
    "    # decrease batch size if running into memory issues when testing\n",
    "    # a bespoke generator is passed to avoid reproducibility issues\n",
    "    shuffle=False, drop_last=False, batch_size=10000, generator=torch.Generator())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then define a small convolutional neural network that will serve as our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MnistCnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistCnn, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, we can define a helper method, which, given a model, a loader for iterating through a set of data, and an optimizer for updating the model trains one epoch (i.e., learns going through all the available data once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "def train_epoch(model: torch.nn.Module, loader: DataLoader, optimizer: Optimizer) -> None:\n",
    "    # TODO\n",
    "    model.train()   # set model to training\n",
    "    running_loss = 0.0 # initialize loss\n",
    "    # load data in batches\n",
    "    for data, target in loader:\n",
    "        optimizer.zero_grad() # zero out gradient from before\n",
    "        output = model(data)    # get models predictions\n",
    "        loss = criterion(output, target)    # get difference bewteen ground truth and models predictions\n",
    "        loss.backwards()    # backwards propagation GD\n",
    "        optimizer.step()    # update models weights\n",
    "        running_loss += loss.item() # track loss for each batch\n",
    "    \n",
    "    avg_loss = running_loss / len(loader)\n",
    "    print(f\"Epoch Loss: {avg_loss:.4f}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define another utility method that splits the dataset into several chunks.\n",
    "\n",
    "We assign samples within chunks in an IID (independent and identically distributed) fashion or allow only two labels to exist in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "def split(nr_clients: int, iid: bool, seed: int) -> list[Subset]:\n",
    "    # TODO\n",
    "    # set random seed\n",
    "    npr.seed(seed)\n",
    "\n",
    "    # get indices\n",
    "    dataset_length = len(train_dataset)\n",
    "    indices = list(range(dataset_length))\n",
    "    subset_length = dataset_length // nr_clients\n",
    "\n",
    "    # make sure samples are iid\n",
    "    npr.shuffle(indices)\n",
    "\n",
    "    client_subsets = []\n",
    "    for i in range(0, nr_clients):\n",
    "        # define start and end point from random indices list\n",
    "        start = i*subset_length\n",
    "        if i != nr_clients:\n",
    "            end = i*subset_length + subset_length\n",
    "        else: \n",
    "            end = dataset_length\n",
    "        client_indices = indices[start: end] # get random indices\n",
    "        # create subset from random indices in train data\n",
    "        client_subset = Subset(train_dataset, client_indices)\n",
    "        client_subsets.append(client_subset) # add new subset\n",
    "\n",
    "    return client_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_split = split(100, True, 42)\n",
    "len(sample_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a short class for holding the results of training runs and the parameters used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict, dataclass, field\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RunResult:\n",
    "    algorithm: str\n",
    "    n: int      # number of clients\n",
    "    c: float    # client_fraction\n",
    "    b: int      # take -1 as inf\n",
    "    e: int      # nr_local_epochs\n",
    "    lr: float   # printed as lowercase eta\n",
    "    seed: int\n",
    "    wall_time: list[float] = field(default_factory=list)\n",
    "    message_count: list[int] = field(default_factory=list)\n",
    "    test_accuracy: list[float] = field(default_factory=list)\n",
    "\n",
    "    def as_df(self, skip_wtime=True) -> DataFrame:\n",
    "        self_dict = {\n",
    "            k.capitalize().replace(\"_\", \" \"): v\n",
    "            for k, v in asdict(self).items()}\n",
    "\n",
    "        if self_dict[\"B\"] == -1:\n",
    "            self_dict[\"B\"] = \"\\N{INFINITY}\"\n",
    "\n",
    "        df = DataFrame({\"Round\": range(1, len(self.wall_time) + 1), **self_dict})\n",
    "        df = df.rename(columns={\"Lr\": ETA})\n",
    "        if skip_wtime:\n",
    "            df = df.drop(columns=[\"Wall time\"])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an abstract class as a template for all distributed learning clients, defining a method for outputting an update after training a given model on local data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class Client(ABC):\n",
    "    def __init__(self, client_data: Subset, batch_size: int) -> None:\n",
    "        self.model = MnistCnn().to(device)\n",
    "        self.generator = torch.Generator()\n",
    "        self.loader_train = DataLoader(\n",
    "            client_data, batch_size=batch_size, shuffle=True,\n",
    "            drop_last=False, generator=self.generator)\n",
    "\n",
    "    @abstractmethod\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the flip side, a server needs to be able to run the (distributed) training process for a given number of rounds and test the current model it possesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server(ABC):\n",
    "    def __init__(self, lr: float, batch_size: int, seed: int) -> None:\n",
    "        self.clients: list[Client]\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = seed\n",
    "        torch.manual_seed(seed)\n",
    "        self.model = MnistCnn().to(device)\n",
    "\n",
    "    @abstractmethod\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        ...\n",
    "\n",
    "    def test(self) -> float:\n",
    "        # TODO\n",
    "        self.model.eval()\n",
    "        evaluation = model(test_loader)\n",
    "        \n",
    "        corr_pred = 0\n",
    "        all_samples = 0\n",
    "        loss = 0.0\n",
    "        test_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in loader:\n",
    "                optimizer.zero_grad() # zero out gradient from before\n",
    "                output = self.model(data)    # get models predictions\n",
    "                loss = F.cross_entropy(output, target)    # get difference bewteen ground truth and models predictions\n",
    "                test_loss += loss.item()\n",
    "                _, prediction = torch.max(output, 1)\n",
    "                corr_pred += (prediciton == target)\n",
    "                all_samples += target.size(0)\n",
    "        avg_loss = test_loss / len(self.test_loader)\n",
    "        accuracy = corr_pred / all_samples\n",
    "        print(f\"Epoch Loss: {avg_loss:.4f}\")\n",
    "        print(f\"Epoch Loss: {accuracy:.4f}\")\n",
    "        return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the previously defined server template, we can even formulate a centralized variant, which does not involve clients, as a precursor to distributed versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "from torch.optim import SGD\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class CentralizedServer(Server):\n",
    "    def __init__(self, lr: float, batch_size: int, seed: int) -> None:\n",
    "        super().__init__(lr, batch_size, seed)\n",
    "        self.optimizer = SGD(params=self.model.parameters(), lr=lr)\n",
    "        self.generator = torch.Generator()\n",
    "        self.loader_train = DataLoader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=True,\n",
    "            drop_last=False, generator=self.generator)\n",
    "        self.clients = []\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        # TODO\n",
    "        start = perf_counter() \n",
    "\n",
    "        RunResult(100, 0, 0, e=nr_rounds, lr=lr, seed=seed, 0, 0., 0)\n",
    "        stop = perf_counter()\n",
    "        print(\"Elapsed time in seconds:\", stop - start)\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centralized_server = CentralizedServer(0.5, 1024, 42)\n",
    "result_centralized = centralized_server.run(5)\n",
    "centralized_df = result_centralized.as_df()\n",
    "centralized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend the template with some setup steps common to all decentralized algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecentralizedServer(Server):\n",
    "    def __init__(\n",
    "            self, lr: float, batch_size: int, client_subsets: list[Subset],\n",
    "            client_fraction: float, seed: int) -> None:\n",
    "        # TODO\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two federated learning algorithms from the paper follow, alongside an overview of metric plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the FedSGD algorithm, the baseline from the paper, we first need to define the client, and we choose to pass gradients from the client as the update result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientClient(Client):\n",
    "    def __init__(self, client_data: Subset) -> None:\n",
    "        super().__init__(client_data, len(client_data))\n",
    "\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        # TODO\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the corresponding server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedSgdGradientServer(DecentralizedServer):\n",
    "    def __init__(\n",
    "            self, lr: float,\n",
    "            client_subsets: list[Subset], client_fraction: float, seed: int) -> None:\n",
    "        super().__init__(lr, -1, client_subsets, client_fraction, seed)\n",
    "        self.optimizer = SGD(params=self.model.parameters(), lr=lr)\n",
    "        self.clients = [GradientClient(subset) for subset in client_subsets]\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        # TODO\n",
    "        return RunResult(\"\", 0, 0., 0, 0, 0., 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fedsgd_gradient_server = FedSgdGradientServer(0.02, sample_split, 0.2, 42)\n",
    "result_fedsgd_gradient = fedsgd_gradient_server.run(5)\n",
    "fedsgd_gradient_df = result_fedsgd_gradient.as_df()\n",
    "fedsgd_gradient_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FedAvg algorithm is the paper's main contribution, requiring a client that passes around weights instead of gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightClient(Client):\n",
    "    def __init__(self, client_data: Subset, lr: float, batch_size: int, nr_epochs: int) -> None:\n",
    "        super().__init__(client_data, batch_size)\n",
    "        self.optimizer = SGD(params=self.model.parameters(), lr=lr)\n",
    "        self.nr_epochs = nr_epochs\n",
    "\n",
    "    def update(self, weights: list[torch.Tensor], seed: int) -> list[torch.Tensor]:\n",
    "        # TODO\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following that, we define the actual server code for the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedAvgServer(DecentralizedServer):\n",
    "    def __init__(\n",
    "            self, lr: float, batch_size: int, client_subsets: list[Subset],\n",
    "            client_fraction: float, nr_local_epochs: int, seed: int) -> None:\n",
    "        super().__init__(lr, batch_size, client_subsets, client_fraction, seed)\n",
    "        self.name = \"FedAvg\"\n",
    "        self.nr_local_epochs = nr_local_epochs\n",
    "        self.clients = [\n",
    "            WeightClient(subset, lr, batch_size, nr_local_epochs)\n",
    "            for subset in client_subsets]\n",
    "\n",
    "    def run(self, nr_rounds: int) -> RunResult:\n",
    "        # TODO\n",
    "        return RunResult(\"\", 0, 0., 0, 0, 0., 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fedavg_server = FedAvgServer(0.02, 200, sample_split, 0.2, 2, 42)\n",
    "result_fedavg = fedavg_server.run(5)\n",
    "fedavg_df = result_fedavg.as_df()\n",
    "fedavg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we look at a quick example of plotting the accuracy per round of the two algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.concat([fedavg_df, fedsgd_gradient_df], ignore_index=True)\n",
    "ax = sns.lineplot(df, x=\"Round\", y=\"Test accuracy\", hue=\"Algorithm\", seed=0)\n",
    "_ = ax.set_xticks(df[\"Round\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
